{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "\n",
    "from spacy.language import Language\n",
    "from spacy_language_detection import LanguageDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/all_songs_with_lyrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics(lyrics: str) -> str:\n",
    "    \"\"\"\n",
    "        Clean up lyrics:\n",
    "            remove beginning up to and including the first occurrence of \"Lyrics\"\n",
    "            remove everything between []\n",
    "            remove numbers+Embed at the end\n",
    "    \"\"\"\n",
    "    if not pd.isnull(lyrics):\n",
    "        # remove beginning up to and including the first occurrence of \"Lyrics\"\n",
    "        beginning_index = lyrics.find(\"Lyrics\") + len(\"Lyrics\")\n",
    "        new_lyrics = lyrics[beginning_index:]\n",
    "        \n",
    "        # remove everything between [], like [Refrain]\n",
    "        # This doesn't work with nested brackets\n",
    "        new_lyrics = re.sub(\"[\\[].*?[\\]]\", \"\", new_lyrics)\n",
    "\n",
    "        # remove numbers and Embed at the end of the Lyrics, e.g. 11Embed\n",
    "        new_lyrics = re.sub(\"[0-9]*Embed$\", \"\", new_lyrics)\n",
    "        return new_lyrics\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df[\"clean_lyrics\"] = df.apply(lambda song: clean_lyrics(song[\"lyrics\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_lyrics\"].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lyrics\"].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you run into spacy error, you will need to install the language package:\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea from this blog: https://towardsdatascience.com/4-python-libraries-to-detect-english-and-non-english-language-c82ad3efd430\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector(seed=42)  # We use the seed 42\n",
    "\n",
    "nlp_model = spacy.load(\"en_core_web_sm\")\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp_model.add_pipe('language_detector', last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language table downloaded from\n",
    "# https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes\n",
    "language_map = (\n",
    "    pd.read_csv(\"data/languages.csv\", delimiter=';')\n",
    "    .rename(columns={\"ISO language name\": \"language\", \"ISO-639-1-Code\": \"language_code\"})\n",
    "    .set_index(\"language_code\")\n",
    "    .to_dict()\n",
    "    [\"language\"]\n",
    ")\n",
    "# {'ab': 'Abkhazian',\n",
    "#  'aa': 'Afar',\n",
    "#  'af': 'Afrikaans',\n",
    "#  'ak': 'Akan',\n",
    "#  'sq': 'Albanian'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_language(text: str) -> str:\n",
    "    \"\"\"return language estimated by nlp_model, this is in ISO 639-1 codes\"\"\"\n",
    "    doc = nlp_model(text)\n",
    "    language_code = doc._.language.get(\"language\", None)\n",
    "    return language_map.get(language_code, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"language\"] = df.apply(lambda song: get_language(song[\"clean_lyrics\"]) if not pd.isnull(song[\"clean_lyrics\"]) else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"has_lyrics\"] = ~df[\"clean_lyrics\"].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"playlist\", \"has_lyrics\", \"language\"], dropna=False).count()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[\"language\"] == \"Indonesian\"][\"clean_lyrics\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"artist_names\", \"name\", \"playlist\", \"lyrics\", \"clean_lyrics\", \"has_lyrics\", \"language\"]].to_csv(\"data/all_songs_with_lyrics_cleaned.csv\", index_label=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"data/all_songs_with_lyrics_cleaned.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apres-ski",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "478056a9e1633caa1bb96a31d3f3e9f69efd98b6bb24dc34c33b3d104d8e79c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
